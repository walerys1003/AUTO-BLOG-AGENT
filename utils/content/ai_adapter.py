"""
AI Adapter Module

This module provides a unified interface for making requests to various AI completion models through
OpenRouter, with fallback to direct provider APIs when needed. Also includes a MockAdapter for testing.

The module also provides factory functions for obtaining appropriate AI service instances.
"""
import json
import logging
import os
import random
import requests
from typing import Dict, Any, Optional, List

from config import Config

# Configure logging
logger = logging.getLogger(__name__)

def get_openrouter_api_key():
    """Get OpenRouter API key from environment or config"""
    # Check environment first
    key = os.environ.get('OPENROUTER_API_KEY')
    if key:
        return key
    
    # Fallback to config
    if hasattr(Config, 'OPENROUTER_API_KEY') and Config.OPENROUTER_API_KEY:
        return Config.OPENROUTER_API_KEY
    
    # No hardcoded key - raise error if not found
    raise ValueError("OPENROUTER_API_KEY not found in environment or config")

def get_ai_completion(
    system_prompt: str,
    user_prompt: str,
    model: str = "anthropic/claude-3.5-sonnet",
    max_tokens: int = 2000,
    temperature: float = 0.7,
    response_format: Optional[Dict[str, str]] = None,
    max_retries: int = 3,
) -> str:
    """
    Get completion from AI model with retry mechanism for rate limiting.
    In production, raises exception on API failure after all retries exhausted.
    MockAdapter is DISABLED by default to prevent publishing placeholder content.
    
    Args:
        system_prompt: System instructions for the AI
        user_prompt: User message/query
        model: Model to use (default: anthropic/claude-3.5-sonnet)
        max_tokens: Maximum tokens to generate
        temperature: Temperature for generation
        response_format: Optional response format specification (e.g. {"type": "json_object"})
        max_retries: Maximum number of retries for rate limiting (default: 3)
        
    Returns:
        Generated text as string
        
    Raises:
        Exception: If OpenRouter API fails after all retries and MockAdapter is disabled
    """
    import time
    
    # Check if MockAdapter is explicitly enabled (for testing only)
    use_mock = os.environ.get('USE_MOCK_ADAPTER', 'false').lower() == 'true'
    
    # Retry mechanism with exponential backoff
    for attempt in range(max_retries):
        try:
            # Try OpenRouter API
            response = openrouter_call(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                response_format=response_format
            )
            
            if response:
                if attempt > 0:
                    logger.info(f"âœ… OpenRouter API succeeded on retry attempt {attempt + 1}/{max_retries}")
                return response
                
        except Exception as e:
            error_msg = str(e)
            is_rate_limit = "rate limit" in error_msg.lower() or "429" in error_msg
            is_server_error = "503" in error_msg or "502" in error_msg or "temporarily unavailable" in error_msg.lower()
            is_timeout = "timeout" in error_msg.lower()
            
            # Check if error is retryable
            is_retryable = is_rate_limit or is_server_error or is_timeout
            
            if is_retryable and attempt < max_retries - 1:
                # Exponential backoff: 2s, 5s, 12s
                wait_time = 2 ** (attempt + 1)
                logger.warning(f"âš ï¸  OpenRouter API error (attempt {attempt + 1}/{max_retries}): {error_msg}")
                logger.warning(f"â³ Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
                continue
            else:
                # Last attempt or non-retryable error
                logger.error(f"ğŸš¨ OpenRouter API call failed after {attempt + 1} attempts: {error_msg}")
                
                # In production (MockAdapter disabled), re-raise the exception
                if not use_mock:
                    logger.error("âŒ PRODUCTION MODE: MockAdapter is DISABLED. Stopping workflow to prevent publishing placeholder content.")
                    logger.error("ğŸ’¡ To enable MockAdapter for testing, set USE_MOCK_ADAPTER=true environment variable.")
                    raise Exception(f"OpenRouter API failed after {attempt + 1} retries and MockAdapter is disabled: {error_msg}")
                
                # Only use MockAdapter if explicitly enabled (testing)
                logger.warning("âš ï¸ TESTING MODE: Using MockAdapter (USE_MOCK_ADAPTER=true)")
                if is_rate_limit:
                    logger.info("Using MockAdapter due to OpenRouter rate limit")
                elif is_server_error:
                    logger.info("Using MockAdapter due to OpenRouter service issues")
                else:
                    logger.info("Using MockAdapter due to OpenRouter API error")
                break
    
    # MockAdapter fallback (only in testing mode)
    logger.info("Generating content using fallback MockAdapter")
    mock = MockAdapter()
    return mock.get_completion(
        system_prompt=system_prompt,
        user_prompt=user_prompt,
        model=model,
        max_tokens=max_tokens,
        temperature=temperature
    )

def openrouter_call(
    system_prompt: str,
    user_prompt: str,
    model: str = "anthropic/claude-3.5-sonnet",
    max_tokens: int = 2000,
    temperature: float = 0.7,
    response_format: Optional[Dict[str, str]] = None,
) -> str:
    """
    Make a request to OpenRouter API.
    
    Args:
        system_prompt: System instructions for the AI
        user_prompt: User message/query
        model: Model to use
        max_tokens: Maximum tokens to generate
        temperature: Temperature for generation
        response_format: Optional response format specification (e.g. {"type": "json_object"})
        
    Returns:
        Generated text as string
    """
    api_key = get_openrouter_api_key()
    if not api_key:
        raise ValueError("OpenRouter API key not found")
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://blog-automation-master.ai/"
    }
    
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature
    }
    
    # Add response format if specified
    if response_format:
        data["response_format"] = response_format
    
    try:
        logger.info(f"Making OpenRouter API request with model: {model}")
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=120  # 2 minute timeout for long requests
        )
        
        # Check response status
        if response.status_code != 200:
            logger.error(f"OpenRouter API error: {response.status_code}")
            logger.error(f"Response text: {response.text[:500]}")
            raise Exception(f"OpenRouter API error: {response.status_code}")
        
        # Validate response content type and content
        response_text = response.text.strip()
        content_type = response.headers.get('content-type', '').lower()
        
        # Check if response looks like HTML (common for error pages)
        if response_text.lower().startswith('<!doctype html') or response_text.lower().startswith('<html'):
            logger.error(f"OpenRouter returned HTML error page. Status: {response.status_code}")
            logger.error(f"HTML preview: {response_text[:500]}")
            if response.status_code == 429:
                raise Exception("OpenRouter API rate limit exceeded - please try again in a few minutes")
            elif response.status_code >= 500:
                raise Exception("OpenRouter service is temporarily unavailable - please try again later")
            else:
                raise Exception(f"OpenRouter returned error page (HTTP {response.status_code})")
        
        # Check content type
        if not content_type.startswith('application/json') and not response_text.startswith(('{', '[')):
            logger.error(f"OpenRouter returned non-JSON response. Content-Type: {content_type}")
            logger.error(f"Response text preview: {response_text[:300]}")
            if 'rate limit' in response_text.lower():
                raise Exception("OpenRouter API rate limit exceeded - please try again in a few minutes")
            else:
                raise Exception("OpenRouter returned unexpected response format")
        
        # Parse JSON response
        try:
            response_data = response.json()
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response from OpenRouter: {str(e)}")
            logger.error(f"Response text: {response.text[:300]}")
            raise Exception(f"Invalid JSON response from OpenRouter: {str(e)}")
        
        # Extract content
        if "choices" not in response_data or not response_data["choices"]:
            logger.error("No choices in OpenRouter response")
            logger.error(f"Response data: {response_data}")
            raise Exception("No choices in OpenRouter response")
        
        content = response_data["choices"][0]["message"]["content"]
        logger.info(f"Successfully received response from OpenRouter (length: {len(content)} chars)")
        return content
        
    except requests.exceptions.Timeout:
        logger.error("OpenRouter API request timed out")
        raise Exception("OpenRouter API request timed out - please try again")
    except requests.exceptions.ConnectionError:
        logger.error("Connection error to OpenRouter API")
        raise Exception("Connection error to OpenRouter API - please check network")
    except Exception as e:
        logger.error(f"OpenRouter API call failed: {str(e)}")
        raise

def get_default_ai_service():
    """
    Factory function to get the default AI service for the application.
    
    Currently returns OpenRouterService with appropriate fallback mechanisms.
    This function is used by other modules to get a consistent AI service.
    
    Returns:
        AI service object with completion capabilities
    """
    return OpenRouterService()

class OpenRouterService:
    """Service class for OpenRouter AI API with fallback capabilities"""
    
    def __init__(self, model=None):
        """Initialize the OpenRouter service with optional model override"""
        self.default_model = model or Config.DEFAULT_CONTENT_MODEL
    
    def complete(self, prompt, system_prompt=None, max_tokens=2000, temperature=0.7):
        """
        Generate a completion for the given prompt.
        
        Args:
            prompt: The user prompt/query
            system_prompt: Optional system instructions (defaults to a generic helper)
            max_tokens: Maximum tokens to generate
            temperature: Temperature for generation
            
        Returns:
            Generated text as string
        """
        if system_prompt is None:
            system_prompt = "JesteÅ› pomocnym asystentem AI, ktÃ³ry dostarcza wartoÅ›ciowe i dokÅ‚adne informacje."
            
        return get_ai_completion(
            system_prompt=system_prompt,
            user_prompt=prompt,
            model=self.default_model,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
    def complete_json(self, prompt, system_prompt=None, max_tokens=2000, temperature=0.7):
        """
        Generate a JSON completion for the given prompt.
        
        Args:
            prompt: The user prompt/query
            system_prompt: Optional system instructions (defaults to a generic helper)
            max_tokens: Maximum tokens to generate
            temperature: Temperature for generation
            
        Returns:
            Generated JSON as Python dict
        """
        if system_prompt is None:
            system_prompt = "JesteÅ› pomocnym asystentem AI, ktÃ³ry dostarcza odpowiedzi w formacie JSON."
            
        response = get_ai_completion(
            system_prompt=system_prompt,
            user_prompt=prompt,
            model=self.default_model,
            max_tokens=max_tokens,
            temperature=temperature,
            response_format={"type": "json_object"}
        )
        
        try:
            return json.loads(response)
        except json.JSONDecodeError:
            logger.error(f"Failed to parse JSON response: {response[:200]}...")
            return {"error": "Invalid JSON response", "text": response}

class MockAdapter:
    """Mock adapter for AI completions when API access fails"""
    
    def get_completion(
        self, 
        system_prompt: str, 
        user_prompt: str, 
        model: str = "anthropic/claude-3.5-sonnet", 
        max_tokens: int = 2000,
        temperature: float = 0.7
    ) -> str:
        """
        Provide a deterministic mock response based on the type of prompt.
        
        Args:
            system_prompt: System instructions for the AI
            user_prompt: User message/query
            model: Model to use (ignored in mock)
            max_tokens: Maximum tokens to generate (ignored in mock)
            temperature: Temperature for generation (ignored in mock)
            
        Returns:
            Generated text as string
        """
        # Clean up prompts to analyze what's being requested
        system_lower = system_prompt.lower()
        user_lower = user_prompt.lower()
        
        # Check if JSON format is expected
        json_format = "json" in system_lower and ("{" in system_lower or "}" in system_lower)
        
        # Detect prompt type
        if "plan" in system_lower and "tytuÅ‚" in system_lower:
            # Article title and plan generation
            return self._generate_mock_title_and_plan(user_prompt, json_format)
            
        elif "wstÄ™p" in system_lower or "introduction" in system_lower:
            # Article introduction
            return self._generate_mock_intro(user_prompt)
            
        elif "zakoÅ„cz" in system_lower or "conclusion" in system_lower:
            # Article conclusion
            return self._generate_mock_conclusion(user_prompt)
            
        elif "topic" in system_lower or "temat" in system_lower:
            # Topic generation
            return self._generate_mock_topics(user_prompt, json_format)
            
        elif "paragrafy" in system_lower or "paragraphs" in system_lower:
            # Paragraph generation
            return self._generate_mock_paragraph(user_prompt)
            
        else:
            # Generic response
            return "To jest przykÅ‚adowa odpowiedÅº wygenerowana przez MockAdapter, poniewaÅ¼ poÅ‚Ä…czenie z API AI nie byÅ‚o dostÄ™pne."
    
    def _generate_mock_title_and_plan(self, user_prompt: str, json_format: bool) -> str:
        """Generate a mock title and article plan"""
        # Extract category and topic
        category = ""
        topic = ""
        
        for line in user_prompt.split("\n"):
            if "kategoria:" in line.lower():
                category = line.split(":", 1)[1].strip()
            elif "temat:" in line.lower():
                topic = line.split(":", 1)[1].strip()
        
        if not category:
            category = "OgÃ³lna"
        if not topic:
            topic = "PrzykÅ‚adowy temat"
            
        # Create a deterministic title based on topic
        title = f"{topic.capitalize()} - kompletny przewodnik dla poczÄ…tkujÄ…cych"
        
        # Create a simple plan
        plan = [
            f"Wprowadzenie do {topic}",
            f"NajwaÅ¼niejsze aspekty {topic}",
            f"KorzyÅ›ci wynikajÄ…ce z {topic}",
            f"Praktyczne zastosowania {topic}",
            f"Podsumowanie i wnioski"
        ]
        
        if json_format:
            return json.dumps({
                "title": title,
                "plan": plan
            }, ensure_ascii=False)
        else:
            plan_text = "\n".join([f"- {item}" for item in plan])
            return f"TytuÅ‚: {title}\n\nPlan:\n{plan_text}"
    
    def _generate_mock_intro(self, user_prompt: str) -> str:
        """Generate a mock article introduction"""
        # Extract topic
        topic = ""
        for line in user_prompt.split("\n"):
            if "temat:" in line.lower():
                topic = line.split(":", 1)[1].strip()
            elif "tytuÅ‚:" in line.lower() and not topic:
                topic = line.split(":", 1)[1].strip()
                
        if not topic:
            topic = "tego tematu"
            
        # Generate mock introduction
        return f"""<p>W dzisiejszych czasach coraz wiÄ™cej osÃ³b interesuje siÄ™ tematykÄ… zwiÄ…zanÄ… z {topic}. Nie jest to zaskakujÄ…ce, biorÄ…c pod uwagÄ™ rosnÄ…ce znaczenie tego obszaru w codziennym Å¼yciu. Od podstawowych zastosowaÅ„ po zaawansowane techniki - wiedza z tego zakresu staje siÄ™ niezbÄ™dna dla wielu profesjonalistÃ³w. W tym artykule przyjrzymy siÄ™ najwaÅ¼niejszym aspektom {topic}, ktÃ³re warto poznaÄ‡, niezaleÅ¼nie od poziomu doÅ›wiadczenia.</p>

<p>Zrozumienie fundamentalnych zasad {topic} pozwala nie tylko na efektywniejsze dziaÅ‚anie, ale rÃ³wnieÅ¼ otwiera drzwi do nowych moÅ¼liwoÅ›ci rozwoju. W kolejnych sekcjach omÃ³wimy zarÃ³wno praktyczne zastosowania, jak i teoretyczne podstawy, ktÃ³re pomogÄ… Ci lepiej zrozumieÄ‡ tÄ™ fascynujÄ…cÄ… dziedzinÄ™.</p>"""
    
    def _generate_mock_conclusion(self, user_prompt: str) -> str:
        """Generate a mock article conclusion"""
        # Extract topic
        topic = ""
        for line in user_prompt.split("\n"):
            if "temat:" in line.lower():
                topic = line.split(":", 1)[1].strip()
            elif "tytuÅ‚:" in line.lower() and not topic:
                topic = line.split(":", 1)[1].strip()
                
        if not topic:
            topic = "tego tematu"
            
        # Generate mock conclusion
        return f"""<p>Zagadnienia zwiÄ…zane z {topic} sÄ… niezwykle istotne w dzisiejszym Å›wiecie. Jak pokazaliÅ›my w tym artykule, odpowiednie podejÅ›cie do tego tematu moÅ¼e przynieÅ›Ä‡ liczne korzyÅ›ci zarÃ³wno w Å¼yciu zawodowym, jak i prywatnym. Warto poÅ›wiÄ™ciÄ‡ czas na gÅ‚Ä™bsze zrozumienie omawianych zagadnieÅ„.</p>

<p>ZachÄ™camy do praktycznego zastosowania zdobytej wiedzy. Najlepszym sposobem na peÅ‚ne przyswojenie informacji o {topic} jest regularne Ä‡wiczenie i eksperymentowanie z poznanymi technikami. PamiÄ™taj, Å¼e rozwÃ³j w tej dziedzinie to proces ciÄ…gÅ‚y â€“ bÄ…dÅº otwarty na nowe informacje i nie bÃ³j siÄ™ zadawaÄ‡ pytaÅ„. Twoje zaangaÅ¼owanie z pewnoÅ›ciÄ… przyniesie oczekiwane rezultaty!</p>"""
    
    def _generate_mock_topics(self, user_prompt: str, json_format: bool) -> str:
        """Generate mock topics for a category"""
        # Extract category
        category = ""
        for line in user_prompt.split("\n"):
            if "kategoria:" in line.lower():
                category = line.split(":", 1)[1].strip()
                
        if not category:
            category = "OgÃ³lna"
            
        # Generate deterministic topics based on category
        base_topics = [
            f"Podstawy {category} dla poczÄ…tkujÄ…cych",
            f"Zaawansowane techniki w {category}",
            f"Historia rozwoju {category} na przestrzeni lat",
            f"Najnowsze trendy w {category} w 2025 roku",
            f"Jak efektywnie wykorzystaÄ‡ {category} w codziennym Å¼yciu",
            f"10 najczÄ™stszych bÅ‚Ä™dÃ³w popeÅ‚nianych przy {category}",
            f"PorÃ³wnanie rÃ³Å¼nych podejÅ›Ä‡ do {category}",
            f"PrzyszÅ‚oÅ›Ä‡ {category} - prognozy ekspertÃ³w",
            f"WpÅ‚yw technologii na rozwÃ³j {category}",
            f"Praktyczny przewodnik po {category}"
        ]
        
        # Generate 20 topics by adding variations
        all_topics = base_topics.copy()
        for topic in base_topics:
            variations = [
                f"Jak {topic.lower()}",
                f"{topic} - praktyczne wskazÃ³wki",
                f"{topic} w kontekÅ›cie biznesowym",
                f"{topic} dla profesjonalistÃ³w",
                f"{topic} - mity i fakty"
            ]
            all_topics.extend(variations[:2])  # Add only first 2 variations to avoid too many
            
        # Shuffle and limit to 20
        random.shuffle(all_topics)
        topics = all_topics[:20]
        
        if json_format:
            return json.dumps(topics, ensure_ascii=False)
        else:
            return "\n".join([f"- {topic}" for topic in topics])
    
    def _generate_mock_paragraph(self, user_prompt: str) -> str:
        """Generate a mock paragraph for an article section"""
        # Extract topic and section
        topic = ""
        section = ""
        
        for line in user_prompt.split("\n"):
            if "temat:" in line.lower():
                topic = line.split(":", 1)[1].strip()
            elif "sekcja:" in line.lower() or "section:" in line.lower():
                section = line.split(":", 1)[1].strip()
            elif "tytuÅ‚ sekcji:" in line.lower():
                section = line.split(":", 1)[1].strip()
                
        if not topic:
            topic = "tego tematu"
        if not section:
            section = "tej sekcji"
            
        # Generate mock paragraph
        return f"""<p>W kontekÅ›cie {topic}, {section} stanowi jeden z kluczowych elementÃ³w, ktÃ³ry warto dokÅ‚adnie przeanalizowaÄ‡. Eksperci w tej dziedzinie podkreÅ›lajÄ…, Å¼e zrozumienie podstawowych zasad jest niezbÄ™dne do osiÄ…gniÄ™cia sukcesu. Badania pokazujÄ…, Å¼e osoby, ktÃ³re systematycznie rozwijajÄ… swoje umiejÄ™tnoÅ›ci w tym zakresie, osiÄ…gajÄ… znacznie lepsze rezultaty niÅ¼ ci, ktÃ³rzy podchodzÄ… do tematu powierzchownie.</p>

<p>Istnieje kilka sprawdzonych metod, ktÃ³re mogÄ… pomÃ³c w efektywnym opanowaniu {section}. Po pierwsze, regularna praktyka jest niezastÄ…piona - nawet 15 minut dziennie moÅ¼e przynieÅ›Ä‡ znaczÄ…ce efekty w dÅ‚uÅ¼szej perspektywie. Po drugie, warto korzystaÄ‡ z dostÄ™pnych zasobÃ³w edukacyjnych, takich jak kursy online, ksiÄ…Å¼ki czy poradniki. Po trzecie, cenna jest wymiana doÅ›wiadczeÅ„ z innymi osobami zainteresowanymi tematykÄ… {topic}.</p>

<p>W praktycznym zastosowaniu {section} moÅ¼emy wyrÃ³Å¼niÄ‡ trzy gÅ‚Ã³wne podejÅ›cia. Pierwsze koncentruje siÄ™ na teoretycznych aspektach i budowaniu solidnych podstaw. Drugie podejÅ›cie kÅ‚adzie nacisk na praktyczne Ä‡wiczenia i rozwiÄ…zywanie konkretnych problemÃ³w. Trzecie Å‚Ä…czy oba wczeÅ›niejsze, tworzÄ…c zrÃ³wnowaÅ¼onÄ… metodÄ™ nauki. WybÃ³r odpowiedniego podejÅ›cia zaleÅ¼y od indywidualnych preferencji oraz specyfiki zagadnieÅ„ zwiÄ…zanych z {topic}.</p>"""